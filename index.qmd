---
title: "Towards Automatic Personal Value Estimation in Song Lyrics with Large Language Models"
---

This is a companion repository for our ISMIR 2025 submission. What follows are additional plots that didn't make it into the manuscript with accompanying explanations. 

# Model Selection, and Run Number Estimation: Pilot Study

To select a sub-set of models for our primary study, we first ran a pilot. 6 LLMs were selected, and prompted to extract scores of each of the 10 Schwartz values for the 14 song lyrics we used in our pilot. 

To estimate intra-model reliability, we collected scores from each model 10 times, and estimated intra-class coefficients, type 2. Although our primary analysis involves type 2k, where the expectation is that the estimand is the mean of ratings from several raters selected from a population of raters, we also estimated type 2, where the estimand is one of absolute agreement rather than general consensus. 

Type 2 gives us an idea of how much the individual ratings agree. Although they approach the typical threshold of .75 for most values in some of the models, they largely fail. We thus conclude we will likely need multiple runs per model. 

![](images/pilot_llm_ICC2.png){fig-align="center"}

We see most models achieve above threshold reliability with 10 runs, with some showing better results than others. 

![](images/pilot_llm_ICC2k.png){fig-align="center"}

In general, we observe that mean ratings from the 10 runs per model show moderate to high correlations with the means per 10 runs of other models. 

![](images/pilot_llm_overall_cor.png){fig-align="center"}

We computed means from participants in two ways. As discussed in the paper, we could leave "NA" responses in the survey as they are, or convert them to 0s. Correlations in the pilot data seem very similar independent of approach. 

![](images/pilot_llm_participant_overall_cor.png){fig-align="center"}

We also examine correlations by value. We see moderate to high correlations overall, with gemma showing most correlations above .8. 

![](images/pilot_llm_participant_byvalue_cor.png)

We see similar results if we treat "NA" values as '0's:

![](images/pilot_llm_participant_0na_byvalue_cor.png)

To determine which models to use and the number of runs we take a bootstrap approach (see paper for description). We observe that gemma, phi, and qwen seem to reach appropriate levels of reliability in about 3 runs, and show relatively high correlations with mean scores from participants ratings. 

![](images/pilot_llm_bootstrap_ICC2k.png)

# LLM correlations with Participant ratings: Main Study

We first asses the reliability of our subset of LLMs over three runs. Overall we see that the models achieve satisfactory reliability for almost all values, with phi and qwen showing relatively poorer scores on CONFORMITY, and phi scores on UNIVERSALISM.


![](images/wave_llm_ICC2k.png)

The means of 3 runs for the three model scores correlate moderately with each other. 

![](images/wave_llm_overall_cor.png)

They correlate moderately overall with means from participant ratings. 

![](images/wave_llm_participant_overall_cor.png)

And we see overall moderate to strong correlations by value with participant mean ratings:

![](images/wave_llm_participant_byvalue_cor.png)

Also when we treat NA values as 0:

![](images/wave_llm_participant_0na_byvalue_cor.png)
