---
title: "Towards Automatic Personal Value Estimation in Song Lyrics with Large Language Models"
---

This is a companion repository for our ISMIR 2025 submission. What follows is material from the publication and additional plots that didn't make it into the manuscript with accompanying explanations. 

# Participants

We asked participants in our pilot study (n=100) about their lyric preferences, and whether they think it affects thier music listening behavior. 

![](images/participant_survey.png){fig-align="center"}

We asked the same participants how confident they were in their ratings, and how subjective they thought the task was. Although participants generally indicate high confidence in their ratings, they also indicate that they see this as a subjective task. 

::: {.panel-tabset}

# Confidence
![](images/participant_confidence.png)

# Subjectivity
![](images/participant_subjectivty.png)
:::

Means from participant ratings in our main wave of annotation data collection generally conformed to expectations in terms of patterns in the MDS plot. As explained in the paper, the test is to see whether values appear next to appropriate neighboring values. In nearly all cases, ours do. 

![](images/participant_MDS_plot.png)

# Model Selection, and Run Number Estimation: Pilot Study

To select a sub-set of models for our primary study, we first ran a pilot. 6 LLMs were selected, and prompted to extract scores of each of the 10 Schwartz values for the 14 song lyrics we used in our pilot. 

To estimate intra-model reliability, we collected scores from each model 10 times, and estimated intra-class coefficients, type 2. Although our primary analysis involves type 2k, where the expectation is that the estimand is the mean of ratings from several raters selected from a population of raters, we also estimated type 2, where the estimand is one of absolute agreement rather than general consensus. 

Type 2 gives us an idea of how much the individual ratings agree. Although they approach the typical threshold of .75 for most values in some of the models, they largely fail. We thus conclude we will likely need multiple runs per model. 

We see most models achieve above threshold reliability with 10 runs, in terms of absolute agreement (ICC2), and certainly with general consensus (ICC2k). 

::: {.panel-tabset}

## Absolute Agreement (ICC2) by model, by value

![](images/pilot_llm_ICC2.png){fig-align="center"}

## Mean of k ratings agreement (ICC2k) by model, by value

![](images/pilot_llm_ICC2k.png){fig-align="center"}

:::

![](images/pilot_llm_overall_cor.png){fig-align="center"}

We computed means from participants in two ways. As discussed in the paper, we could leave "NA" responses in the survey as they are, or convert them to 0s. Correlations in the pilot data seem very similar independent of approach. 

![](images/pilot_llm_participant_overall_cor.png){fig-align="center"}

We also examine correlations by value. We see moderate to high correlations overall, with gemma showing most correlations above .8. We see similar results if we treat “NA” values as ’0’s. 

::: {.panel-tabset}

## NAs unchanged

![](images/pilot_llm_participant_byvalue_cor.png)

## NAs as "0"s


![](images/pilot_llm_participant_0na_byvalue_cor.png)

:::

To determine which models to use and the number of runs we take a bootstrap approach (see paper for description). We observe that gemma, phi, and qwen seem to reach appropriate levels of reliability in about 3 runs, and show relatively high correlations with mean scores from participants ratings. 

![](images/pilot_llm_bootstrap_ICC2k.png)

# LLM correlations with Participant ratings: Main Study

Our main study presents results using 400 song lyrics. We gathered a median 15 ratings from participants in the US, stratified by the 4 most common ethnicities. We then compute means per value per song. We then prompt our subset of 3 LLMs to rate each song 3 times per value. 

We first asses the reliability of our subset of LLMs over three runs. Overall we see that the models achieve satisfactory reliability for almost all values, with phi and qwen showing relatively poorer scores on CONFORMITY, and phi scores on UNIVERSALISM.


![](images/wave_llm_ICC2k.png)

The means of 3 runs for the three model scores correlate moderately with each other. 

![](images/wave_llm_overall_cor.png)

They correlate moderately overall with means from participant ratings. 

![](images/wave_llm_participant_overall_cor.png)


And we see overall moderate to strong correlations by value with participant mean ratings when NAs are left unchanged, and also when we treat NA values as 0. 

::: {.panel-tabset}

# NAs unchanged

![](images/wave_llm_participant_byvalue_cor.png)

# NAs as "0"s

![](images/wave_llm_participant_0na_byvalue_cor.png)

:::

Prior work has suggested that the actual 'ground truth' is a list of values. In other words, that each person has a hierarchy of these 10 values. To further explore this with our lyrics, we treat each lyric excerpt as a 'person', by computing a ranked list from the mean ratings of each value. We then do the same with our LLM ratings, and compute ranked list correlations per song. Here we plot the distribution of ranked list correlations, per model. 

![](images/wave_llm_participant_overall_kendall.png)

Prior work has suggested that correlations of .2 are meaningful. Here we look at what proportion exceed that threshold, per model. 

```{r wave_llm_participant_kendall_proportions, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(here)

table <- readRDS(here("images", "wave_llm_participant_kendall_proportion.RDS"))
table
```
